data:
    image_size: 256
    channels: 3
    logit_transform: false
    uniform_dequantization: false
    gaussian_dequantization: false
    rescaled: true
    num_workers: 32

model:
    in_channels: 3
    out_channels: 3
    num_channels: 256
    num_heads: 4
    num_res_blocks: 2
    attention_resolutions: "32,16,8"
    dropout: 0.0
    resamp_with_conv: True
    learn_sigma: True
    use_scale_shift_norm: true
    use_fp16: true
    resblock_updown: true
    num_heads_upsample: -1
    var_type: 'fixedsmall'
    num_head_channels: 64
    image_size: 256
    class_cond: false
    use_new_attention_order: false

diffusion:
    beta_schedule: linear
    beta_start: 0.0001
    beta_end: 0.02
    num_diffusion_timesteps: 1000

sampling:
    batch_size: 32
    last_only: True
